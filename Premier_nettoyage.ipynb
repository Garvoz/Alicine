{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTATION DES BASES DE DONNEES BRUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code à éxécuter sans les nrows\n",
    "link1 = \"./BD/name.basics.tsv.gz\"\n",
    "link2 = \"./BD/title.akas.tsv.gz\"\n",
    "link3 = \"./BD/title.basics.tsv.gz\"\n",
    "link4 = \"./BD/title.crew.tsv.gz\"\n",
    "link5 = \"./BD/title.episode.tsv.gz\"\n",
    "link6 = \"./BD/title.principals.tsv.gz\"\n",
    "link7 = \"./BD/title.ratings.tsv.gz\"\n",
    "df_basic_name = pd.read_csv(link1, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_akas = pd.read_csv(link2, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_basics = pd.read_csv(link3, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_crew = pd.read_csv(link4, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_episode = pd.read_csv(link5, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_principals = pd.read_csv(link6, sep = \"\\t\", compression = \"gzip\", nrows = 1000)\n",
    "df_t_ratings = pd.read_csv(link7, sep = \"\\t\", compression = \"gzip\", nrows = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE DE LA TABLE BASIC NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie :\n",
    "df_basic_name_Clean = df_basic_name.copy()\n",
    "\n",
    "# filtrage de toutes les valeurs du primaryName non null\n",
    "df_basic_name_Clean = df_basic_name_Clean[df_basic_name_Clean['primaryName'].isna() == False]\n",
    "\n",
    "#Transformation des valeurs \\N en NAN\n",
    "df_basic_name_Clean['deathYear'] = df_basic_name_Clean['deathYear'].replace('\\\\N', np.nan)\n",
    "df_basic_name_Clean[\"deathYear\"]=df_basic_name_Clean[\"deathYear\"].astype('Int32')\n",
    "df_basic_name_Clean['birthYear'] = df_basic_name_Clean['birthYear'].replace('\\\\N', np.nan)\n",
    "df_basic_name_Clean[\"birthYear\"]=df_basic_name_Clean[\"birthYear\"].astype('Int32')\n",
    "df_basic_name_Clean['primaryProfession'] = df_basic_name_Clean['primaryProfession'].replace('\\\\N', np.nan)\n",
    "df_basic_name_Clean['knownForTitles'] = df_basic_name_Clean['knownForTitles'].replace('\\\\N', np.nan)\n",
    "\n",
    "# Filtrage pour ne garder que les acteurs/actrices/réalisateurs:\n",
    "df_basic_name_Clean = df_basic_name_Clean[(df_basic_name_Clean['primaryProfession'].str.contains('actor'))|(df_basic_name_Clean['primaryProfession'].str.contains('actress'))|(df_basic_name_Clean['primaryProfession'].str.contains('director'))]\n",
    "\n",
    "#Transformation colonnes \"primaryProfession\" et \"knownForTitles\" en liste:\n",
    "df_basic_name_Clean[\"primaryProfession\"]= df_basic_name_Clean[\"primaryProfession\"].apply(lambda x : x.strip().split(',') if isinstance(x,str) else x)\n",
    "df_basic_name_Clean[\"knownForTitles\"]= df_basic_name_Clean[\"knownForTitles\"].apply(lambda y : y.strip().split(',') if isinstance(y,str) else y)\n",
    "\n",
    "#Filtrage pour élilminer ceux qui sont morts il y a trop longtemps:\n",
    "df_basic_name_Clean = df_basic_name_Clean[df_basic_name_Clean[\"deathYear\"] > 1960]\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_basic_name_Clean.to_csv('df_basic_name_clean.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE AKAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie :\n",
    "df_t_akas_Clean = df_t_akas.copy()\n",
    "\n",
    "# suppression des colonnes qui ne nous intéressent pas :\n",
    "df_t_akas_Clean = df_t_akas_Clean.drop(columns = ['ordering', 'region', 'language', 'types','attributes', 'isOriginalTitle'])\n",
    "\n",
    "# Aggrégation des différents titres en une liste pour chaque ID:\n",
    "df_t_akas_Clean = df_t_akas_Clean.groupby('titleId').agg(list).reset_index()\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_akas_Clean.to_csv(\"df_t_akas_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une copie :\n",
    "df_t_basics_Clean = df_t_basics.copy()\n",
    "\n",
    "#Nettoyage des données:\n",
    "df_t_basics_Clean.duplicated().sum() #==> 0 : aucune ligne duppliquée\n",
    "df_t_basics_Clean[df_t_basics_Clean['genres'].isna()] # => affiche 633 lignes en NAN\n",
    "df_t_basics_Clean.isna().sum() # ==> affiche 19 ligne en NA dans primaryTitle et originalTitle \n",
    "\n",
    "df_t_basics_Clean.dropna(subset=['genres'], inplace=True) # Suppression des lignes en NA de la colonne genre donc 633\n",
    "df_t_basics_Clean.dropna(subset=['originalTitle'], inplace=True) # suppression des 19 lignes\n",
    "\n",
    "#Transformation des valeurs \\N en NAN\n",
    "df_t_basics_Clean['startYear'] = df_t_basics_Clean['startYear'].replace('\\\\N', np.nan)\n",
    "df_t_basics_Clean['endYear'] = df_t_basics_Clean['endYear'].replace('\\\\N', np.nan)\n",
    "df_t_basics_Clean['runtimeMinutes'] = df_t_basics_Clean['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "df_t_basics_Clean['genres'] = df_t_basics_Clean['genres'].replace('\\\\N', np.nan)\n",
    "\n",
    "#Listage des genres:\n",
    "df_t_basics_Clean['genres'] = df_t_basics_Clean['genres'].apply(lambda x: x.strip().split(',') if isinstance(x, str) else [] )\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_basics_Clean.to_csv(\"df_t_basics_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE CREW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie :\n",
    "df_t_crew_Clean = df_t_crew.copy()\n",
    "\n",
    "# Exploration des erreurs:\n",
    "valNull = df_t_crew_Clean.isna().sum() #0 valeurs\n",
    "duplicated = df_t_crew_Clean.duplicated().sum()  # 0valeurs\n",
    "\n",
    "#Création de listes:\n",
    "df_t_crew_Clean['directors'] = df_t_crew_Clean['directors'].apply(lambda x: x.strip().split(',') if isinstance(x,str) else x )\n",
    "df_t_crew_Clean['writers'] = df_t_crew_Clean['writers'].apply(lambda x: x.strip().split(',') if isinstance(x,str) else x)\n",
    "\n",
    "#Transformation des valeurs \\N en NAN\n",
    "df_t_crew_Clean['directors'] = df_t_crew_Clean['directors'].replace(r'\\N', np.nan)\n",
    "df_t_crew_Clean['writers'] = df_t_crew_Clean['writers'].replace(r'\\N', np.nan)\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_crew_Clean.to_csv(\"df_t_crew_clean.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE EPISODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie :\n",
    "df_t_episode_Clean= df_t_episode.copy()\n",
    "\n",
    "# Exploration des erreurs:\n",
    "valNull = df_t_episode_Clean.isna().sum() #0 valeurs\n",
    "duplicated = df_t_episode_Clean.duplicated().sum()  # 0valeurs mais y a \\N à traiter\n",
    "\n",
    "#Etape 1 : Transformation des valeurs \\N en NAN\n",
    "df_t_episode_Clean['seasonNumber'] = df_t_episode_Clean ['seasonNumber'].replace(r'\\N', np.nan)\n",
    "df_t_episode_Clean['episodeNumber'] = df_t_episode_Clean ['episodeNumber'].replace(r'\\N', np.nan)\n",
    "\n",
    "#création d'une colonne qui servira lors du merge avec title basic pour distinguer les séries.\n",
    "df_t_episode_Clean['IdSerie'] = True \n",
    "\n",
    "# Etape intremédiaire : copy pour la suppression de colonne:\n",
    "df_t_episode_Clean1 = df_t_episode_Clean.copy()\n",
    "\n",
    "#Etape : suppression des colonne qu'on va pas utiliser:\n",
    "df_t_episode_Clean1 = df_t_episode_Clean1.drop(columns = ['seasonNumber', 'episodeNumber'])\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_episode_Clean1.to_csv('df_t_episode_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE PRINCIPALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie :\n",
    "df_t_principals_Clean = df_t_principals.copy()\n",
    "\n",
    "#Suppression des colonnes : 'ordering', 'job', 'characters'\n",
    "df_t_principals_Clean = df_t_principals_Clean.drop(columns =['ordering', 'job', 'characters'])\n",
    "\n",
    "#Suppression des duplicates dûs aux lignes 'characters'\n",
    "df_t_principals_Clean = df_t_principals_Clean.drop_duplicates()\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_principals_Clean.to_csv('df_t_principals_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE TABLE TITLE RATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pas de filtre particulier a faire, simple vérification de la présence de valeurs null:\n",
    "\n",
    "# Création d'une copie :\n",
    "df_t_ratings_Clean = df_t_ratings.copy()\n",
    "\n",
    "df_t_ratings_Clean.isna().sum()\n",
    "\n",
    "#Export nouvelle table en csv:\n",
    "df_t_ratings_Clean.to_csv('df_t_ratings_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
